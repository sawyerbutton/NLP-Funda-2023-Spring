{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SIHdSF2HrGma"
      },
      "outputs": [],
      "source": [
        "openai_api_key='YOUR_API_KEY'\n",
        "# ä½¿ç”¨ä½ è‡ªå·±çš„OpenAI API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mFDD4Dwfrbly",
        "outputId": "53535409-7d31-48c0-dbeb-f7f92edd6363"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>.container { width:90% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
        "# å¸®åŠ©ä½ çš„ipynbçœ‹èµ·æ¥æ›´èˆ’æœ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- åœ¨æˆ‘ä»¬å¼€å§‹å‰ï¼Œå®‰è£…éœ€è¦çš„ä¾èµ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78mgFx67se_j",
        "outputId": "eb932300-81a9-4b81-e3e0-1c90d713e3f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.174-py3-none-any.whl (869 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m869.7/869.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, multidict, marshmallow, frozenlist, async-timeout, yarl, typing-inspect, openapi-schema-pydantic, marshmallow-enum, aiosignal, dataclasses-json, aiohttp, langchain\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 dataclasses-json-0.5.7 frozenlist-1.3.3 langchain-0.0.174 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.8.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.7\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction\n",
        "\n",
        "æˆ‘ä»¬èƒ½ä½¿ç”¨ Lang Chain å®ç°å“ªäº›èƒ½åŠ›ï¼Œåˆ—ä¸¾çš„ä¸æ˜¯å…¨éƒ¨ï¼Œä½†æ˜¯éƒ½æ˜¯å…·å¤‡ä»£è¡¨æ€§çš„ç‰¹æ€§èƒ½åŠ›\n",
        "\n",
        "- Summarization - å¯¹æ–‡æœ¬/èŠå¤©å†…å®¹çš„é‡ç‚¹å†…å®¹æ€»ç»“\n",
        "- Question and Answering Over Documents - ä½¿ç”¨æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŸºäºæ–‡æ¡£å†…å®¹è¿›è¡Œé—®ç­”\n",
        "- Extraction - ä»æ–‡æœ¬å†…å®¹ä¸­æŠ½å–ç»“æ„åŒ–çš„å†…å®¹\n",
        "- Evaluation - åˆ†æå¹¶è¯„ä¼°LLMè¾“å‡ºçš„ç»“æœçš„å¥½å\n",
        "- Querying Tabular Data - ä»æ•°æ®åº“/ç±»æ•°æ®åº“å†…å®¹ä¸­æŠ½å–æ•°æ®ä¿¡æ¯\n",
        "- Code Understanding - åˆ†æä»£ç ï¼Œå¹¶ä»ä»£ç ä¸­è·å–é€»è¾‘ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒQA\n",
        "- Interacting with APIs - é€šè¿‡å¯¹APIæ–‡æ¡£çš„é˜…è¯»ï¼Œç†è§£APIæ–‡æ¡£å¹¶å‘çœŸå®ä¸–ç•Œè°ƒç”¨APIè·å–çœŸå®æ•°æ®\n",
        "- Chatbots - å…·å¤‡è®°å¿†èƒ½åŠ›çš„èŠå¤©æœºå™¨äººæ¡†æ¶ï¼ˆæœ‰UIäº¤äº’èƒ½åŠ›ï¼‰\n",
        "- Agents - ä½¿ç”¨LLMsè¿›è¡Œä»»åŠ¡åˆ†æå’Œå†³ç­–ï¼Œå¹¶è°ƒç”¨å·¥å…·æ‰§è¡Œå†³ç­–\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2IarVI6ptBbD"
      },
      "source": [
        "## Summarization\n",
        "\n",
        "- æ‰”ç»™LLMä¸€æ®µæ–‡æœ¬ï¼Œè®©ä»–ç»™ä½ ç”Ÿæˆæ€»ç»“å¯ä»¥è¯´æ˜¯æœ€å¸¸è§çš„åœºæ™¯ä¹‹ä¸€äº†\n",
        "- ç›®å‰æœ€ç«çš„åº”ç”¨åº”è¯¥æ˜¯ chatPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GUqRpCNrm1-",
        "outputId": "f524f6da-5e43-4ed8-c892-94a34701627f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain.utilities.powerbi:Could not import azure.core python package.\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:169: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/llms/openai.py:695: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Summaries Of Short Text\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "llm = OpenAI(temperature=0, model_name = 'gpt-3.5-turbo', openai_api_key=openai_api_key) # åˆå§‹åŒ–LLMæ¨¡å‹\n",
        "\n",
        "# åˆ›å»ºæ¨¡æ¿\n",
        "template = \"\"\"\n",
        "%INSTRUCTIONS:\n",
        "Please summarize the following piece of text.\n",
        "Respond in a manner that a 5 year old would understand.\n",
        "\n",
        "%TEXT:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ª Lang Chain Prompt æ¨¡æ¿ï¼Œç¨åå¯ä»¥æ’å…¥å€¼\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=template,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JgkE3t3JscMj"
      },
      "outputs": [],
      "source": [
        "confusing_text = \"\"\"\n",
        "For the next 130 years, debate raged.\n",
        "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
        "â€œThe problem is that when you look up close at the anatomy, itâ€™s evocative of a lot of different things, but itâ€™s diagnostic of nothing,â€ says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
        "â€œAnd itâ€™s so damn big that when whenever someone says itâ€™s something, everyone elseâ€™s hackles get up: â€˜How could you have a lichen 20 feet tall?â€™â€\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en5ZKBmisz5O",
        "outputId": "dcb5cc7d-0ee5-40e0-ba5b-507d76c22a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------- Prompt Begin -------\n",
            "\n",
            "%INSTRUCTIONS:\n",
            "Please summarize the following piece of text.\n",
            "Respond in a manner that a 5 year old would understand.\n",
            "\n",
            "%TEXT:\n",
            "\n",
            "For the next 130 years, debate raged.\n",
            "Some scientists called Prototaxites a lichen, others a fungus, and still others clung to the notion that it was some kind of tree.\n",
            "â€œThe problem is that when you look up close at the anatomy, itâ€™s evocative of a lot of different things, but itâ€™s diagnostic of nothing,â€ says Boyce, an associate professor in geophysical sciences and the Committee on Evolutionary Biology.\n",
            "â€œAnd itâ€™s so damn big that when whenever someone says itâ€™s something, everyone elseâ€™s hackles get up: â€˜How could you have a lichen 20 feet tall?â€™â€\n",
            "\n",
            "\n",
            "------- Prompt End -------\n"
          ]
        }
      ],
      "source": [
        "print (\"------- Prompt Begin -------\")\n",
        "# æ‰“å°æ¨¡æ¿å†…å®¹\n",
        "final_prompt = prompt.format(text=confusing_text)\n",
        "print(final_prompt)\n",
        "\n",
        "print (\"------- Prompt End -------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1Es0gDgs2Gs",
        "outputId": "5b88ccb1-99bc-447d-984a-bac474701808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "People argued for a long time about what Prototaxites was. Some thought it was a lichen, some thought it was a fungus, and some thought it was a tree. But it was hard to tell for sure because it looked like different things up close and it was really, really big.\n"
          ]
        }
      ],
      "source": [
        "output = llm(final_prompt)\n",
        "print (output)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- å¯¹äºæ–‡æœ¬é•¿åº¦è¾ƒçŸ­çš„æ–‡æœ¬æˆ‘ä»¬å¯ä»¥ç›´æ¥è¿™æ ·æ‰§è¡Œsummaryæ“ä½œ\n",
        "- ä½†æ˜¯å¯¹äºæ–‡æœ¬é•¿åº¦è¶…è¿‡lLMæ”¯æŒçš„max token size æ—¶å°†ä¼šé‡åˆ°å›°éš¾\n",
        "- Lang Chain æä¾›äº†å¼€ç®±å³ç”¨çš„å·¥å…·è§£å†³é•¿æ–‡æœ¬çš„é—®é¢˜ï¼šload_summarize_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7DUFpAcZs-dE"
      },
      "outputs": [],
      "source": [
        "# Summaries Of Longer Text\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f8GlcSVtK5n",
        "outputId": "99d16873-8f3d-4b48-84d2-bac5f89a094a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Project Gutenberg eBook of Aliceâ€™s Adventures in Wonderland, by Lewis Carroll\n",
            "\n",
            "This eBook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it unde\n"
          ]
        }
      ],
      "source": [
        "with open('wonderland.txt', 'r') as file:\n",
        "    text = file.read() # æ–‡ç« æœ¬èº«æ˜¯çˆ±ä¸½ä¸æ¢¦æ¸¸ä»™å¢ƒ\n",
        "\n",
        "# æ‰“å°å°è¯´çš„å‰285ä¸ªå­—ç¬¦\n",
        "print (text[:285])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjtfOEvFt7ds",
        "outputId": "35fd6db3-8c32-47c7-c898-ae684bf70610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken # å®‰è£…ç”¨äºåˆ†å‰²æ–‡æœ¬çš„ä¾èµ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noL6AUb1ts2a",
        "outputId": "35228f63-3665-4e2c-d743-51589fc12246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 48613 tokens in your file\n"
          ]
        }
      ],
      "source": [
        "num_tokens = llm.get_num_tokens(text)\n",
        "\n",
        "print (f\"There are {num_tokens} tokens in your file\") \n",
        "# å…¨æ–‡ä¸€å…±4w8è¯\n",
        "# å¾ˆæ˜æ˜¾è¿™æ ·çš„æ–‡æœ¬é‡æ˜¯æ— æ³•ç›´æ¥é€è¿›LLMè¿›è¡Œå¤„ç†å’Œç”Ÿæˆçš„"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "è§£å†³é•¿æ–‡æœ¬çš„æ–¹å¼æ— éæ˜¯'chunking','splitting' åŸæ–‡æœ¬ä¸ºå°çš„æ®µè½/åˆ†å‰²éƒ¨åˆ†\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQsyYfGht2EH",
        "outputId": "5d505565-68d5-4810-85db-a69e2b4da542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You now have 36 docs intead of 1 piece of text\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=5000, chunk_overlap=350)\n",
        "# è™½ç„¶æˆ‘ä½¿ç”¨çš„æ˜¯ RecursiveCharacterTextSplitterï¼Œä½†æ˜¯ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»–å·¥å…·\n",
        "docs = text_splitter.create_documents([text])\n",
        "\n",
        "print (f\"You now have {len(docs)} docs intead of 1 piece of text\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ç°åœ¨å°±éœ€è¦ä¸€ä¸ª Lang Chain å·¥å…·ï¼Œå°†åˆ†æ®µæ–‡æœ¬é€å…¥LLMè¿›è¡Œsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pwvT14EIuf3Q"
      },
      "outputs": [],
      "source": [
        "# è®¾ç½® lang chain\n",
        "# ä½¿ç”¨ map_reduceçš„chain_typeï¼Œè¿™æ ·å¯ä»¥å°†å¤šä¸ªæ–‡æ¡£åˆå¹¶æˆä¸€ä¸ª\n",
        "chain = load_summarize_chain(llm=llm, chain_type='map_reduce') # verbose=True å±•ç¤ºè¿è¡Œæ—¥å¿—"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILwXodN8u_xF",
        "outputId": "644c900f-f61b-485c-9356-8abffd4c7f5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Alice follows a white rabbit down a rabbit hole and finds herself in a strange world full of peculiar characters. She experiences many strange adventures and is asked to settle disputes between the characters. In the end, she is in a court of justice with the King and Queen of Hearts and is questioned by the King. Alice reads a set of verses and has a dream in which she remembers a secret. Project Gutenberg is a library of electronic works founded by Professor Michael S. Hart and run by volunteers.\n"
          ]
        }
      ],
      "source": [
        "# Use it. This will run through the 36 documents, summarize the chunks, then get a summary of the summary.\n",
        "# å…¸å‹çš„map reduceçš„æ€è·¯å»è§£å†³é—®é¢˜ï¼Œå°†æ–‡ç« æ‹†åˆ†æˆå¤šä¸ªéƒ¨åˆ†ï¼Œå†å°†å¤šä¸ªéƒ¨åˆ†åˆ†åˆ«è¿›è¡Œ summarizeï¼Œæœ€åå†è¿›è¡Œ åˆå¹¶ï¼Œå¯¹ summarys è¿›è¡Œ summary\n",
        "output = chain.run(docs)\n",
        "print (output)\n",
        "# Try yourself"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I74h0HtgwA--"
      },
      "source": [
        "## Question & Answering Using Documents As Context\n",
        "\n",
        "ä¸ºäº†ç¡®ä¿LLMèƒ½å¤Ÿæ‰§è¡ŒQAä»»åŠ¡\n",
        "1. éœ€è¦å‘LLMä¼ é€’èƒ½å¤Ÿè®©ä»–å‚è€ƒçš„ä¸Šä¸‹æ–‡ä¿¡æ¯\n",
        "2. éœ€è¦å‘LLMå‡†ç¡®åœ°ä¼ è¾¾æˆ‘ä»¬çš„é—®é¢˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ptZCXLe7vPl0"
      },
      "outputs": [],
      "source": [
        "# æ¦‚æ‹¬æ¥è¯´ï¼Œä½¿ç”¨æ–‡æ¡£ä½œä¸ºä¸Šä¸‹æ–‡è¿›è¡ŒQAç³»ç»Ÿçš„æ„å»ºè¿‡ç¨‹ç±»ä¼¼äº llm(your context + your question) = your answer\n",
        "# Simple Q&A Example\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "J-a5IoExwADi"
      },
      "outputs": [],
      "source": [
        "context = \"\"\"\n",
        "Rachel is 30 years old\n",
        "Bob is 45 years old\n",
        "Kevin is 65 years old\n",
        "\"\"\"\n",
        "\n",
        "question = \"Who is under 40 years old?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89q7fvB7wfu9",
        "outputId": "d19f61dc-68f5-4e08-9fca-4da08f149121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rachel is under 40 years old.\n"
          ]
        }
      ],
      "source": [
        "output = llm(context + question)\n",
        "\n",
        "print (output.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKp2J9kHxhQp",
        "outputId": "efae0b92-c25f-47e9-bfa7-554838a82aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu # éœ€è¦æ³¨æ„ï¼Œfaisså­˜åœ¨GPUå’ŒCPUç‰ˆæœ¬åŸºäºä½ çš„ runtime å®‰è£…å¯¹åº”çš„ç‰ˆæœ¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jqbzqzMBwiXP"
      },
      "outputs": [],
      "source": [
        "# Using Embeddings\n",
        "# åˆ†å‰²åˆ†æ–‡ï¼Œå¯¹åˆ†å—çš„å†…å®¹è¿›è¡Œ embeddingï¼Œå°† embedding å­˜å‚¨åˆ°æ•°æ®åº“ä¸­ï¼Œç„¶åè¿›è¡ŒæŸ¥è¯¢\n",
        "# ç›®æ ‡æ˜¯é€‰æ‹©ç›¸å…³çš„æ–‡æœ¬å—ï¼Œä½†æ˜¯æˆ‘ä»¬åº”è¯¥é€‰æ‹©å“ªäº›æ–‡æœ¬å—å‘¢ï¼Ÿç›®å‰æœ€æµè¡Œçš„æ–¹æ³•æ˜¯åŸºäºæ¯”è¾ƒå‘é‡åµŒå…¥æ¥é€‰æ‹©ç›¸ä¼¼çš„æ–‡æœ¬\n",
        "\n",
        "from langchain import OpenAI\n",
        "\n",
        "# The vectorstore we'll be using\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# The LangChain component we'll use to get the documents\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# The easy document loader for text\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# The embedding engine that will convert our text to vectors\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVJuuoG2xBnS",
        "outputId": "84af0b45-8623-4887-c308-4d7628df2495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have 1 document\n",
            "You have 164014 characters in that document\n"
          ]
        }
      ],
      "source": [
        "loader = TextLoader('wonderland.txt') # è½½å…¥ä¸€ä¸ªé•¿æ–‡æœ¬ï¼Œæˆ‘ä»¬è¿˜æ˜¯ä½¿ç”¨çˆ±ä¸½ä¸æ¼«æ¸¸ä»™å¢ƒè¿™ç¯‡å°è¯´ä½œä¸ºè¾“å…¥\n",
        "doc = loader.load()\n",
        "print (f\"You have {len(doc)} document\")\n",
        "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "81ohG7WpxKNJ"
      },
      "outputs": [],
      "source": [
        "# å°†å°è¯´åˆ†å‰²æˆå¤šä¸ªéƒ¨åˆ†\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
        "docs = text_splitter.split_documents(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FArqtB8yxPZr",
        "outputId": "4d89d204-6d05-4fe6-d300-e40de171c86d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now you have 62 documents that have an average of 2,846 characters (smaller pieces)\n"
          ]
        }
      ],
      "source": [
        "# è·å–å­—ç¬¦çš„æ€»æ•°ï¼Œä»¥ä¾¿å¯ä»¥è®¡ç®—å¹³å‡å€¼\n",
        "num_total_characters = sum([len(x.page_content) for x in docs])\n",
        "\n",
        "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "STNVCrQxxUO8"
      },
      "outputs": [],
      "source": [
        "# è®¾ç½® embedding å¼•æ“\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "# Embed æ–‡æ¡£ï¼Œç„¶åä½¿ç”¨ä¼ªæ•°æ®åº“å°†æ–‡æ¡£å’ŒåŸå§‹æ–‡æœ¬ç»“åˆèµ·æ¥\n",
        "# è¿™ä¸€æ­¥ä¼šå‘ OpenAI å‘èµ· API è¯·æ±‚\n",
        "docsearch = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4KNHfrfdxcx9"
      },
      "outputs": [],
      "source": [
        "# åˆ›å»ºQA-retrieval chain\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G1A1_UI9xvVn",
        "outputId": "b9b600df-96b2-4809-b8d6-067ec909520b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The author describes Alice following a White Rabbit with pink eyes.'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What does the author describe the Alice following with?\"\n",
        "qa.run(query)\n",
        "# è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ£€ç´¢å™¨ä¼šå»è·å–ç±»ä¼¼çš„æ–‡ä»¶éƒ¨åˆ†ï¼Œå¹¶ç»“åˆä½ çš„é—®é¢˜è®© LLM è¿›è¡Œæ¨ç†ï¼Œæœ€åå¾—åˆ°ç­”æ¡ˆ\n",
        "# è¿™ä¸€æ­¥è¿˜æœ‰å¾ˆå¤šå¯ä»¥ç»†ç©¶çš„æ­¥éª¤ï¼Œæ¯”å¦‚å¦‚ä½•é€‰æ‹©æœ€ä½³çš„åˆ†å‰²å¤§å°ï¼Œå¦‚ä½•é€‰æ‹©æœ€ä½³çš„ embedding å¼•æ“ï¼Œå¦‚ä½•é€‰æ‹©æœ€ä½³çš„æ£€ç´¢å™¨ç­‰ç­‰\n",
        "# åŒæ—¶ä¹Ÿå¯ä»¥é€‰æ‹©äº‘ç«¯å‘é‡å­˜å‚¨"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLfoguiz9EY"
      },
      "source": [
        "## Extraction\n",
        "\n",
        "- Extractionæ˜¯ä»ä¸€æ®µæ–‡æœ¬ä¸­è§£ææ•°æ®çš„è¿‡ç¨‹\n",
        "- é€šå¸¸ä¸Extraction parserä¸€èµ·ä½¿ç”¨ï¼Œä»¥æ„å»ºæ•°æ®\n",
        "\n",
        "1. ä»å¥å­ä¸­æå–ç»“æ„åŒ–è¡Œä»¥æ’å…¥æ•°æ®åº“\n",
        "2. ä»é•¿æ–‡æ¡£ä¸­æå–å¤šè¡Œä»¥æ’å…¥æ•°æ®åº“\n",
        "3. ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–å‚æ•°ä»¥è¿›è¡Œ API è°ƒç”¨\n",
        "4. æœ€è¿‘æœ€ç«çš„ Extraction åº“æ˜¯ KOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "sKlFUiuXx_aD"
      },
      "outputs": [],
      "source": [
        "\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# è§£æè¾“å‡ºå¹¶è·å–ç»“æ„åŒ–çš„æ•°æ®\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "\n",
        "chat_model = ChatOpenAI(temperature=0, model='gpt-3.5-turbo', openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JWGf8ICk073y"
      },
      "outputs": [],
      "source": [
        "# Vanilla Extraction\n",
        "instructions = \"\"\"\n",
        "You will be given a sentence with fruit names, extract those fruit names and assign an emoji to them\n",
        "Return the fruit name and emojis in a python dictionary\n",
        "\"\"\"\n",
        "\n",
        "fruit_names = \"\"\"\n",
        "Apple, Pear, this is an kiwi\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjn0cxnZ1Brb",
        "outputId": "64ea2e40-9752-487a-e872-efa0ea183f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Apple': 'ğŸ', 'Pear': 'ğŸ', 'kiwi': 'ğŸ¥'}\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# Make your prompt which combines the instructions w/ the fruit names\n",
        "prompt = (instructions + fruit_names)\n",
        "\n",
        "# Call the LLM\n",
        "output = chat_model([HumanMessage(content=prompt)])\n",
        "\n",
        "print (output.content)\n",
        "print (type(output.content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gImh8_6B1Hst",
        "outputId": "aa8687e6-be97-4e56-8368-e400ae9f9046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Apple': 'ğŸ', 'Pear': 'ğŸ', 'kiwi': 'ğŸ¥'}\n",
            "<class 'dict'>\n"
          ]
        }
      ],
      "source": [
        "output_dict = eval(output.content)\n",
        "\n",
        "print (output_dict)\n",
        "print (type(output_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "rA5hAH3q11zG"
      },
      "outputs": [],
      "source": [
        "# è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªå¸¦æœ‰æ ¼å¼è¯´æ˜çš„æç¤º\n",
        "# è¿™æ ·å°±ä¸éœ€è¦æ‹…å¿ƒæç¤ºå·¥ç¨‹çš„é—®é¢˜äº†ï¼Œå°†è¿™éƒ¨åˆ†å®Œå…¨äº¤ç»™ Lang Chain æ¥æ‰§è¡Œ\n",
        "# å°†LLMçš„è¾“å‡ºè½¬åŒ–ä¸º python å¯¹è±¡\n",
        "\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"artist\", description=\"The name of the musical artist\"),\n",
        "    ResponseSchema(name=\"song\", description=\"The name of the song that the artist plays\")\n",
        "]\n",
        "\n",
        "# è§£æå™¨å°†ä¼šæŠŠLLMçš„è¾“å‡ºä½¿ç”¨æˆ‘å®šä¹‰çš„schemaè¿›è¡Œè§£æå¹¶è¿”å›æœŸå¾…çš„ç»“æ„æ•°æ®ç»™æˆ‘\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzsTB-WK3CSj",
        "outputId": "0ef60a81-11df-47c7-c03b-0c427a9f3572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"artist\": string  // The name of the musical artist\n",
            "\t\"song\": string  // The name of the song that the artist plays\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "o9C10yFv3GF0"
      },
      "outputs": [],
      "source": [
        "# è¿™ä¸ª Prompt ä¸ä¹‹å‰æˆ‘ä»¬æ„å»º Chat Model æ—¶ Prompt ä¸åŒ\n",
        "# è¿™ä¸ª Prompt æ˜¯ä¸€ä¸ª ChatPromptTemplateï¼Œå®ƒä¼šè‡ªåŠ¨å°†æˆ‘ä»¬çš„è¾“å‡ºè½¬åŒ–ä¸º python å¯¹è±¡\n",
        "prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        HumanMessagePromptTemplate.from_template(\"Given a command from the user, extract the artist and song names \\n \\\n",
        "                                                    {format_instructions}\\n{user_prompt}\")  \n",
        "    ],\n",
        "    input_variables=[\"user_prompt\"],\n",
        "    partial_variables={\"format_instructions\": format_instructions}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndEjq-x13Uct",
        "outputId": "647dd66a-f924-483d-9a04-5d732b959059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given a command from the user, extract the artist and song names \n",
            "                                                     The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"artist\": string  // The name of the musical artist\n",
            "\t\"song\": string  // The name of the song that the artist plays\n",
            "}\n",
            "```\n",
            "I really like So Young by Portugal. The Man\n"
          ]
        }
      ],
      "source": [
        "fruit_query = prompt.format_prompt(user_prompt=\"I really like So Young by Portugal. The Man\")\n",
        "print (fruit_query.messages[0].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU01EgAx3Xrl",
        "outputId": "41972c45-4372-4dc6-f7e6-fd25728d3881"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'artist': 'Portugal. The Man', 'song': 'So Young'}\n",
            "<class 'dict'>\n"
          ]
        }
      ],
      "source": [
        "fruit_output = chat_model(fruit_query.to_messages())\n",
        "output = output_parser.parse(fruit_output.content)\n",
        "\n",
        "print (output)\n",
        "print (type(output))\n",
        "# è¿™é‡Œè¦æ³¨æ„çš„æ˜¯ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨çš„ turbo æ¨¡å‹ï¼Œç”Ÿæˆçš„ç»“æœå¹¶ä¸ä¸€å®šæ˜¯æ¯æ¬¡éƒ½ä¸€è‡´çš„\n",
        "# æ›¿æ¢æˆgpt4æ¨¡å‹å¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cu1MzoY7368M"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "- Evaluationæ˜¯å¯¹åº”ç”¨ç¨‹åºçš„è¾“å‡ºè¿›è¡Œè´¨é‡æ£€æŸ¥çš„è¿‡ç¨‹\n",
        "- æ­£å¸¸çš„ã€ç¡®å®šæ€§çš„ä»£ç æœ‰æˆ‘ä»¬å¯ä»¥è¿è¡Œçš„æµ‹è¯•ï¼Œä½†ç”±äºè‡ªç„¶è¯­è¨€çš„ä¸å¯é¢„æµ‹æ€§å’Œå¯å˜æ€§ï¼Œåˆ¤æ–­ LLM çš„è¾“å‡ºæ›´åŠ å›°éš¾\n",
        "- langchain æä¾›äº†ä¸€ç§æ–¹å¼å¸®åŠ©æˆ‘ä»¬å»è§£å†³è¿™ä¸€éš¾é¢˜\n",
        "- å¯¹äºQApipline ç”Ÿæˆçš„summaryè¿›è¡Œè´¨é‡å®¡æŸ¥\n",
        "- å¯¹ Summary piplineçš„ç»“æœè¿›è¡Œæ£€æŸ¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "w787Sqsn3eIm"
      },
      "outputs": [],
      "source": [
        "# Embeddings, store, and retrieval\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Model and doc loader\n",
        "from langchain import OpenAI\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# Eval\n",
        "from langchain.evaluation.qa import QAEvalChain\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYOmSZCx4jTG",
        "outputId": "1ad8ee26-f421-4fb1-87bd-bce0fe2682d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have 1 document\n",
            "You have 164014 characters in that document\n"
          ]
        }
      ],
      "source": [
        "# è¿˜æ˜¯ä½¿ç”¨çˆ±ä¸½ä¸æ¼«æ¸¸ä»™å¢ƒä½œä¸ºæ–‡æœ¬è¾“å…¥\n",
        "loader = TextLoader('wonderland.txt')\n",
        "doc = loader.load()\n",
        "\n",
        "print (f\"You have {len(doc)} document\")\n",
        "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auRa34Lk4qAQ",
        "outputId": "3e60b5a1-1c13-4270-be41-cc9cf2f2f714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Now you have 62 documents that have an average of 2,846 characters (smaller pieces)\n"
          ]
        }
      ],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
        "docs = text_splitter.split_documents(doc)\n",
        "\n",
        "# Get the total number of characters so we can see the average later\n",
        "num_total_characters = sum([len(x.page_content) for x in docs])\n",
        "\n",
        "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WkE1fi_L4tQS"
      },
      "outputs": [],
      "source": [
        "# Embeddings and docstore\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "docsearch = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "v9oya8su4wpZ"
      },
      "outputs": [],
      "source": [
        "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever(), input_key=\"question\")\n",
        "# æ³¨æ„è¿™é‡Œçš„ input_key å‚æ•°ï¼Œè¿™ä¸ªå‚æ•°å‘Šè¯‰äº† chain æˆ‘çš„é—®é¢˜åœ¨å­—å…¸ä¸­çš„å“ªä¸ª key é‡Œ\n",
        "# è¿™æ · chain å°±ä¼šè‡ªåŠ¨å»æ‰¾åˆ°é—®é¢˜å¹¶å°†å…¶ä¼ é€’ç»™ LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "bTUujN3k5OKe"
      },
      "outputs": [],
      "source": [
        "question_answers = [\n",
        "    {'question' : \"Which animal give alice a instruction?\", 'answer' : 'rabbit'},\n",
        "    {'question' : \"What is the author of the book\", 'answer' : 'Elon Mask'}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKqRhrpo51O8",
        "outputId": "e2e539ed-93ba-40fe-d195-4bf3d55efa8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'Which animal give alice a instruction?',\n",
              "  'answer': 'rabbit',\n",
              "  'result': ' The Caterpillar gave Alice instructions.'},\n",
              " {'question': 'What is the author of the book',\n",
              "  'answer': 'Elon Mask',\n",
              "  'result': ' The author of the book is Lewis Carroll.'}]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = chain.apply(question_answers)\n",
        "predictions\n",
        "# ä½¿ç”¨LLMæ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œå¹¶å°†ç­”æ¡ˆä¸æˆ‘æä¾›çš„ç­”æ¡ˆè¿›è¡Œæ¯”è¾ƒï¼Œè¿™é‡Œä¿¡ä»»æˆ‘è‡ªå·±æä¾›çš„äººå·¥ç­”æ¡ˆæ˜¯æ­£ç¡®çš„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6w8L8Qam51g5"
      },
      "outputs": [],
      "source": [
        "# Start your eval chain\n",
        "eval_chain = QAEvalChain.from_llm(llm)\n",
        "\n",
        "graded_outputs = eval_chain.evaluate(question_answers,\n",
        "                                     predictions,\n",
        "                                     question_key=\"question\",\n",
        "                                     prediction_key=\"result\",\n",
        "                                     answer_key='answer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c4HECHp6L8F",
        "outputId": "cb43aa93-ac6f-4075-e785-f30425d6c501"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': ' INCORRECT'}, {'text': ' INCORRECT'}]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graded_outputs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MaUJftcC6aCV"
      },
      "source": [
        "## Querying Tabular Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "dIpb5Hi46OCr"
      },
      "outputs": [],
      "source": [
        "# ä½¿ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢ä¸€ä¸ª SQLite æ•°æ®åº“ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ—§é‡‘å±±æ ‘æœ¨æ•°æ®é›†\n",
        "# Don't run following code if you don't run sqlite and follow db\n",
        "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DiP-LlX6nrh"
      },
      "outputs": [],
      "source": [
        "sqlite_db_path = 'data/San_Francisco_Trees.db'\n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X568YYZ265Pi"
      },
      "outputs": [],
      "source": [
        "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLuuRm4n66NM"
      },
      "outputs": [],
      "source": [
        "db_chain.run(\"How many Species of trees are there in San Francisco?\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ukkWFf7BaS"
      },
      "source": [
        "1. Find which table to use\n",
        "2. Find which column to use\n",
        "3. Construct the correct sql query\n",
        "4. Execute that query\n",
        "5. Get the result\n",
        "6. Return a natural language reponse back\n",
        "\n",
        "confirm LLM result via pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbEX6OVi7Fot"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to the SQLite database\n",
        "connection = sqlite3.connect(sqlite_db_path)\n",
        "\n",
        "# Define your SQL query\n",
        "query = \"SELECT count(distinct qSpecies) FROM SFTrees\"\n",
        "\n",
        "# Read the SQL query into a Pandas DataFrame\n",
        "df = pd.read_sql_query(query, connection)\n",
        "\n",
        "# Close the connection\n",
        "connection.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIgn39RF7T_I"
      },
      "outputs": [],
      "source": [
        "# Display the result in the first column first cell\n",
        "print(df.iloc[0,0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HEBsVmFb7vc7"
      },
      "source": [
        "## Code Understanding\n",
        "\n",
        "- Co-Pilot-esque functionality that can help answer questions from a specific library, help you generate new code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Gz9kF0vk7yxi"
      },
      "outputs": [],
      "source": [
        "# Helper to read local files\n",
        "import os\n",
        "\n",
        "# Vector Support\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "# Model and chain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Text splitters\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-3.5-turbo', openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "AgEUoDi_713p"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(disallowed_special=(), openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "vhmKMttD73oC"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/drive/MyDrive/thefuzz-master'\n",
        "docs = []\n",
        "\n",
        "# Go through each folder\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    \n",
        "    # Go through each file\n",
        "    for file in filenames:\n",
        "        try: \n",
        "            # Load up the file as a doc and split\n",
        "            loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
        "            docs.extend(loader.load_and_split())\n",
        "        except Exception as e: \n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWickZcQ9r98",
        "outputId": "6a2977db-6f24-4ef9-817b-c3be97b330f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have 175 documents\n",
            "\n",
            "------ Start Document ------\n",
            "from timeit import timeit\n",
            "import math\n",
            "import csv\n",
            "\n",
            "iterations = 100000\n",
            "\n",
            "\n",
            "reader = csv.DictReader(open('data/titledata.csv'), delimiter='|')\n",
            "titles = [i['custom_title'] for i in reader]\n",
            "title_blob = '\\n'.join(titles)\n",
            "\n",
            "\n",
            "cirque_strings = [\n",
            "    \"cirque du soleil - zarkana - las vegas\",\n",
            "    \"cirque du sol\n"
          ]
        }
      ],
      "source": [
        "print (f\"You have {len(docs)} documents\\n\")\n",
        "print (\"------ Start Document ------\")\n",
        "print (docs[0].page_content[:300])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Ybg6PTit9xJH"
      },
      "outputs": [],
      "source": [
        "docsearch = FAISS.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "E8rXOXmw-Tpu"
      },
      "outputs": [],
      "source": [
        "# Get our retriever ready\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "lqaXfVf2-VK2"
      },
      "outputs": [],
      "source": [
        "query = \"What function do I use if I want to find the most similar item in a list of items?\"\n",
        "output = qa.run(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfbsq_x7-bND",
        "outputId": "9fd9d866-964c-4077-e23e-2cb85c3aeb66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You can use the `process.extractOne()` function from `thefuzz` package to find the most similar item in a list of items. For example:\n",
            "\n",
            "```\n",
            "from thefuzz import process\n",
            "\n",
            "choices = [\"New York Yankees\", \"Boston Red Sox\", \"Chicago Cubs\", \"Los Angeles Dodgers\"]\n",
            "query = \"new york mets vs atlanta braves\"\n",
            "\n",
            "best_match = process.extractOne(query, choices)\n",
            "print(best_match)\n",
            "```\n",
            "\n",
            "This will output:\n",
            "\n",
            "```\n",
            "('New York Yankees', 50)\n",
            "```\n",
            "\n",
            "Where `('New York Yankees', 50)` means that the closest match found was \"New York Yankees\" with a score of 50 (out of 100).\n"
          ]
        }
      ],
      "source": [
        "print (output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn8_2xL3-gF5",
        "outputId": "94a4fdd2-22f7-4302-f9bc-aa896cca7da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "process.extractOne(query, choices)\n"
          ]
        }
      ],
      "source": [
        "query = \"Can you write the code to use the process.extractOne() function? Only respond with code. No other text or explanation\"\n",
        "output = qa.run(query)\n",
        "print(output)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FOD5KzPE-vRf"
      },
      "source": [
        "## Interacting with APIs\n",
        "\n",
        "- å¦‚æœä½ éœ€è¦çš„æ•°æ®æˆ–æ“ä½œåœ¨ API ä¹‹åï¼Œå°±éœ€è¦LLMèƒ½å¤Ÿå’ŒAPIè¿›è¡Œäº¤äº’\n",
        "- åˆ°è¿™ä¸ªç¯èŠ‚ï¼Œå°±ä¸ Agents å’Œ Plugins æ¯æ¯ç›¸å…³äº†\n",
        "- Demoå¯èƒ½å¾ˆç®€å•ï¼Œä½†æ˜¯åŠŸèƒ½å¯èƒ½å¾ˆå¤æ‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "zawoKRWy-v1Y"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import APIChain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "JMes_6Xo_Mhh"
      },
      "outputs": [],
      "source": [
        "api_docs = \"\"\"\n",
        "\n",
        "BASE URL: https://restcountries.com/\n",
        "\n",
        "API Documentation:\n",
        "\n",
        "The API endpoint /v3.1/name/{name} Used to find informatin about a country. All URL parameters are listed below:\n",
        "    - name: Name of country - Ex: italy, france\n",
        "    \n",
        "The API endpoint /v3.1/currency/{currency} Uesd to find information about a region. All URL parameters are listed below:\n",
        "    - currency: 3 letter currency. Example: USD, COP\n",
        "    \n",
        "Woo! This is my documentation\n",
        "\"\"\"\n",
        "\n",
        "chain_new = APIChain.from_llm_and_api_docs(llm, api_docs, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "gdI8gkyi_N2t",
        "outputId": "b2da73bf-6bf6-41a9-c816-28bc8ef7b1d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/name/france\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"France\",\"official\":\"French Republic\",\"nativeName\":{\"fra\":{\"official\":\"RÃ©publique franÃ§aise\",\"common\":\"France\"}}},\"tld\":[\".fr\"],\"cca2\":\"FR\",\"ccn3\":\"250\",\"cca3\":\"FRA\",\"cioc\":\"FRA\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"EUR\":{\"name\":\"Euro\",\"symbol\":\"â‚¬\"}},\"idd\":{\"root\":\"+3\",\"suffixes\":[\"3\"]},\"capital\":[\"Paris\"],\"altSpellings\":[\"FR\",\"French Republic\",\"RÃ©publique franÃ§aise\"],\"region\":\"Europe\",\"subregion\":\"Western Europe\",\"languages\":{\"fra\":\"French\"},\"translations\":{\"ara\":{\"official\":\"Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±ÙŠØ© Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©\",\"common\":\"ÙØ±Ù†Ø³Ø§\"},\"bre\":{\"official\":\"Republik FraÃ±s\",\"common\":\"FraÃ±s\"},\"ces\":{\"official\":\"FrancouzskÃ¡ republika\",\"common\":\"Francie\"},\"cym\":{\"official\":\"French Republic\",\"common\":\"France\"},\"deu\":{\"official\":\"FranzÃ¶sische Republik\",\"common\":\"Frankreich\"},\"est\":{\"official\":\"Prantsuse Vabariik\",\"common\":\"Prantsusmaa\"},\"fin\":{\"official\":\"Ranskan tasavalta\",\"common\":\"Ranska\"},\"fra\":{\"official\":\"RÃ©publique franÃ§aise\",\"common\":\"France\"},\"hrv\":{\"official\":\"Francuska Republika\",\"common\":\"Francuska\"},\"hun\":{\"official\":\"Francia KÃ¶ztÃ¡rsasÃ¡g\",\"common\":\"FranciaorszÃ¡g\"},\"ita\":{\"official\":\"Repubblica francese\",\"common\":\"Francia\"},\"jpn\":{\"official\":\"ãƒ•ãƒ©ãƒ³ã‚¹å…±å’Œå›½\",\"common\":\"ãƒ•ãƒ©ãƒ³ã‚¹\"},\"kor\":{\"official\":\"í”„ë‘ìŠ¤ ê³µí™”êµ­\",\"common\":\"í”„ë‘ìŠ¤\"},\"nld\":{\"official\":\"Franse Republiek\",\"common\":\"Frankrijk\"},\"per\":{\"official\":\"Ø¬Ù…Ù‡ÙˆØ±ÛŒ ÙØ±Ø§Ù†Ø³Ù‡\",\"common\":\"ÙØ±Ø§Ù†Ø³Ù‡\"},\"pol\":{\"official\":\"Republika Francuska\",\"common\":\"Francja\"},\"por\":{\"official\":\"RepÃºblica Francesa\",\"common\":\"FranÃ§a\"},\"rus\":{\"official\":\"Ğ¤Ñ€Ğ°Ğ½Ñ†ÑƒĞ·ÑĞºĞ°Ñ Ğ ĞµÑĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°\",\"common\":\"Ğ¤Ñ€Ğ°Ğ½Ñ†Ğ¸Ñ\"},\"slk\":{\"official\":\"FrancÃºzska republika\",\"common\":\"FrancÃºzsko\"},\"spa\":{\"official\":\"RepÃºblica francÃ©s\",\"common\":\"Francia\"},\"srp\":{\"official\":\"Ğ¤Ñ€Ğ°Ğ½Ñ†ÑƒÑĞºĞ° Ğ ĞµĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°\",\"common\":\"Ğ¤Ñ€Ğ°Ğ½Ñ†ÑƒÑĞºĞ°\"},\"swe\":{\"official\":\"Republiken Frankrike\",\"common\":\"Frankrike\"},\"tur\":{\"official\":\"Fransa Cumhuriyeti\",\"common\":\"Fransa\"},\"urd\":{\"official\":\"Ø¬Ù…ÛÙˆØ±ÛŒÛ ÙØ±Ø§Ù†Ø³\",\"common\":\"ÙØ±Ø§Ù†Ø³\"},\"zho\":{\"official\":\"æ³•å…°è¥¿å…±å’Œå›½\",\"common\":\"æ³•å›½\"}},\"latlng\":[46.0,2.0],\"landlocked\":false,\"borders\":[\"AND\",\"BEL\",\"DEU\",\"ITA\",\"LUX\",\"MCO\",\"ESP\",\"CHE\"],\"area\":551695.0,\"demonyms\":{\"eng\":{\"f\":\"French\",\"m\":\"French\"},\"fra\":{\"f\":\"FranÃ§aise\",\"m\":\"FranÃ§ais\"}},\"flag\":\"\\uD83C\\uDDEB\\uD83C\\uDDF7\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/g7QxxSFsWyTPKuzd7\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/1403916\"},\"population\":67391582,\"gini\":{\"2018\":32.4},\"fifa\":\"FRA\",\"car\":{\"signs\":[\"F\"],\"side\":\"right\"},\"timezones\":[\"UTC-10:00\",\"UTC-09:30\",\"UTC-09:00\",\"UTC-08:00\",\"UTC-04:00\",\"UTC-03:00\",\"UTC+01:00\",\"UTC+02:00\",\"UTC+03:00\",\"UTC+04:00\",\"UTC+05:00\",\"UTC+10:00\",\"UTC+11:00\",\"UTC+12:00\"],\"continents\":[\"Europe\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/fr.png\",\"svg\":\"https://flagcdn.com/fr.svg\",\"alt\":\"The flag of France is composed of three equal vertical bands of blue, white and red.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/fr.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/fr.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[48.87,2.33]},\"postalCode\":{\"format\":\"#####\",\"regex\":\"^(\\\\d{5})$\"}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' France is an officially-assigned, independent country located in Western Europe. Its capital is Paris and its official language is French. Its currency is the Euro (â‚¬). It has a population of 67,391,582 and its borders are with Andorra, Belgium, Germany, Italy, Luxembourg, Monaco, Spain, and Switzerland.'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain_new.run('Can you tell me information about france?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "-cIEtsLW_Q8Q",
        "outputId": "7a3c1d8d-4807-49aa-d4fb-e9fcb6186f86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new APIChain chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/currency/COP\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"Colombia\",\"official\":\"Republic of Colombia\",\"nativeName\":{\"spa\":{\"official\":\"RepÃºblica de Colombia\",\"common\":\"Colombia\"}}},\"tld\":[\".co\"],\"cca2\":\"CO\",\"ccn3\":\"170\",\"cca3\":\"COL\",\"cioc\":\"COL\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"COP\":{\"name\":\"Colombian peso\",\"symbol\":\"$\"}},\"idd\":{\"root\":\"+5\",\"suffixes\":[\"7\"]},\"capital\":[\"BogotÃ¡\"],\"altSpellings\":[\"CO\",\"Republic of Colombia\",\"RepÃºblica de Colombia\"],\"region\":\"Americas\",\"subregion\":\"South America\",\"languages\":{\"spa\":\"Spanish\"},\"translations\":{\"ara\":{\"official\":\"Ø¬Ù…Ù‡ÙˆØ±ÙŠØ© ÙƒÙˆÙ„ÙˆÙ…Ø¨ÙŠØ§\",\"common\":\"ÙƒÙˆÙ„ÙˆÙ…Ø¨ÙŠØ§\"},\"bre\":{\"official\":\"Republik Kolombia\",\"common\":\"Kolombia\"},\"ces\":{\"official\":\"KolumbijskÃ¡ republika\",\"common\":\"Kolumbie\"},\"cym\":{\"official\":\"Gweriniaeth Colombia\",\"common\":\"Colombia\"},\"deu\":{\"official\":\"Republik Kolumbien\",\"common\":\"Kolumbien\"},\"est\":{\"official\":\"Colombia Vabariik\",\"common\":\"Colombia\"},\"fin\":{\"official\":\"Kolumbian tasavalta\",\"common\":\"Kolumbia\"},\"fra\":{\"official\":\"RÃ©publique de Colombie\",\"common\":\"Colombie\"},\"hrv\":{\"official\":\"Republika Kolumbija\",\"common\":\"Kolumbija\"},\"hun\":{\"official\":\"Kolumbiai KÃ¶ztÃ¡rsasÃ¡g\",\"common\":\"Kolumbia\"},\"ita\":{\"official\":\"Repubblica di Colombia\",\"common\":\"Colombia\"},\"jpn\":{\"official\":\"ã‚³ãƒ­ãƒ³ãƒ“ã‚¢å…±å’Œå›½\",\"common\":\"ã‚³ãƒ­ãƒ³ãƒ“ã‚¢\"},\"kor\":{\"official\":\"ì½œë¡¬ë¹„ì•„ ê³µí™”êµ­\",\"common\":\"ì½œë¡¬ë¹„ì•„\"},\"nld\":{\"official\":\"Republiek Colombia\",\"common\":\"Colombia\"},\"per\":{\"official\":\"Ø¬Ù…Ù‡ÙˆØ±ÛŒ Ú©Ù„Ù…Ø¨ÛŒØ§\",\"common\":\"Ú©Ù„Ù…Ø¨ÛŒØ§\"},\"pol\":{\"official\":\"Republika Kolumbii\",\"common\":\"Kolumbia\"},\"por\":{\"official\":\"RepÃºblica da ColÃ´mbia\",\"common\":\"ColÃ´mbia\"},\"rus\":{\"official\":\"Ğ ĞµÑĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ° ĞšĞ¾Ğ»ÑƒĞ¼Ğ±Ğ¸Ñ\",\"common\":\"ĞšĞ¾Ğ»ÑƒĞ¼Ğ±Ğ¸Ñ\"},\"slk\":{\"official\":\"KolumbijskÃ¡ republika\",\"common\":\"Kolumbia\"},\"spa\":{\"official\":\"RepÃºblica de Colombia\",\"common\":\"Colombia\"},\"srp\":{\"official\":\"Ğ ĞµĞ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ° ĞšĞ¾Ğ»ÑƒĞ¼Ğ±Ğ¸Ñ˜Ğ°\",\"common\":\"ĞšĞ¾Ğ»ÑƒĞ¼Ğ±Ğ¸Ñ˜Ğ°\"},\"swe\":{\"official\":\"Republiken Colombia\",\"common\":\"Colombia\"},\"tur\":{\"official\":\"Kolombiya Cumhuriyeti\",\"common\":\"Kolombiya\"},\"urd\":{\"official\":\"Ø¬Ù…ÛÙˆØ±ÛŒÛ Ú©ÙˆÙ„Ù…Ø¨ÛŒØ§\",\"common\":\"Ú©ÙˆÙ„Ù…Ø¨ÛŒØ§\"},\"zho\":{\"official\":\"å“¥ä¼¦æ¯”äºšå…±å’Œå›½\",\"common\":\"å“¥ä¼¦æ¯”äºš\"}},\"latlng\":[4.0,-72.0],\"landlocked\":false,\"borders\":[\"BRA\",\"ECU\",\"PAN\",\"PER\",\"VEN\"],\"area\":1141748.0,\"demonyms\":{\"eng\":{\"f\":\"Colombian\",\"m\":\"Colombian\"},\"fra\":{\"f\":\"Colombienne\",\"m\":\"Colombien\"}},\"flag\":\"\\uD83C\\uDDE8\\uD83C\\uDDF4\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/RdwTG8e7gPwS62oR6\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/120027\"},\"population\":50882884,\"gini\":{\"2019\":51.3},\"fifa\":\"COL\",\"car\":{\"signs\":[\"CO\"],\"side\":\"right\"},\"timezones\":[\"UTC-05:00\"],\"continents\":[\"South America\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/co.png\",\"svg\":\"https://flagcdn.com/co.svg\",\"alt\":\"The flag of Colombia is composed of three horizontal bands of yellow, blue and red, with the yellow band twice the height of the other two bands.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/co.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/co.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[4.71,-74.07]}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The currency of Colombia is the Colombian peso (COP), symbolized by the \"$\" sign.'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain_new.run('Can you tell me about the currency COP?')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gL3XHt4U_dqp"
      },
      "source": [
        "## Chatbots\n",
        "\n",
        "- èŠå¤©æœºå™¨äººä½¿ç”¨äº†ä¹‹å‰æåŠè¿‡çš„å¾ˆå¤šå·¥å…·ï¼Œä¸”æœ€é‡è¦çš„æ˜¯å¢åŠ äº†ä¸€ä¸ªé‡è¦çš„å·¥å…·ï¼šè®°å¿†åŠ›\n",
        "- ä¸ç”¨æˆ·è¿›è¡Œå®æ—¶äº¤äº’ï¼Œä¸ºç”¨æˆ·æä¾›è‡ªç„¶è¯­è¨€é—®é¢˜çš„å¹³æ˜“è¿‘äººçš„ UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "bgceKFnd_aHP"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "# Chat specific components\n",
        "from langchain.memory import ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "piN2tjyw_2Xk"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"\n",
        "You are a chatbot that is unhelpful.\n",
        "Your goal is to not help the user but only make jokes.\n",
        "Take what the user is saying and make a joke out of it\n",
        "\n",
        "{chat_history}\n",
        "Human: {human_input}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"human_input\"], \n",
        "    template=template\n",
        ")\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "XmRaX6u4ADIb"
      },
      "outputs": [],
      "source": [
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(openai_api_key=openai_api_key), \n",
        "    prompt=prompt, \n",
        "    verbose=True, \n",
        "    memory=memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "VVc-YVHiAFWN",
        "outputId": "4ea06df4-e200-4d3e-a7f8-b75e033fdf15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a chatbot that is unhelpful.\n",
            "Your goal is to not help the user but only make jokes.\n",
            "Take what the user is saying and make a joke out of it\n",
            "\n",
            "\n",
            "Human: Is an pear a fruit or vegetable?\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' An pear is a fruit, but a vegetable-pear is a pun-ishable offense!'"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "llm_chain.predict(human_input=\"Is an pear a fruit or vegetable?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "zwcE5P9-AM3k",
        "outputId": "22e9f486-d1fe-4261-9e1b-8d32de7e62fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a chatbot that is unhelpful.\n",
            "Your goal is to not help the user but only make jokes.\n",
            "Take what the user is saying and make a joke out of it\n",
            "\n",
            "Human: Is an pear a fruit or vegetable?\n",
            "AI:  An pear is a fruit, but a vegetable-pear is a pun-ishable offense!\n",
            "Human: What was one of the fruits I first asked you about?\n",
            "AI:  It was an pear - but you can't pear-y the consequences if you don't remember!\n",
            "Human: What was one of the fruits I first asked you about?\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" An pear - but don't let it get to your core!\""
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_chain.predict(human_input=\"What was one of the fruits I first asked you about?\")\n",
        "# è¿™é‡Œç¬¬äºŒä¸ªé—®é¢˜çš„ç­”æ¡ˆæ˜¯æ¥è‡ªäºç¬¬ä¸€ä¸ªç­”æ¡ˆæœ¬èº«çš„ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨åˆ°äº† memory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lgkgX-3mAtQr"
      },
      "source": [
        "## Agents\n",
        "\n",
        "- ä»£ç†æ˜¯ LLM ä¸­æœ€çƒ­é—¨çš„ ğŸ”¥ ä¸»é¢˜ä¹‹ä¸€\n",
        "- ä»£ç†å¯ä»¥æŸ¥çœ‹æ•°æ®ã€æ¨æ–­ä¸‹ä¸€æ­¥åº”è¯¥é‡‡å–ä»€ä¹ˆè¡ŒåŠ¨ï¼Œå¹¶é€šè¿‡å·¥å…·ä¸ºæ‚¨æ‰§è¡Œè¯¥è¡ŒåŠ¨, æ˜¯ä¸€ä¸ªå…·å¤‡AIæ™ºèƒ½çš„å†³ç­–è€…\n",
        "- Run programs autonomously without the need for human input\n",
        "- å°å¿ƒä½¿ç”¨ Auto GPT, ä¼šè¿…é€Ÿæ¶ˆè€—æ‰ä½ å¤§é‡çš„token usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "37dcZ16fARFV"
      },
      "outputs": [],
      "source": [
        "# Helpers\n",
        "import os\n",
        "import json\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "# Agent imports\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "\n",
        "# Tool imports\n",
        "from langchain.agents import Tool\n",
        "from langchain.utilities import GoogleSearchAPIWrapper\n",
        "from langchain.utilities import TextRequestsWrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "8SjEdp2QBMOK"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GOOGLE_CSE_ID\"] = \"a3499f99563e249f3\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA6vdCpxvbHn-5ubAwQ2mTdZBej8Zw6pFU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "2hgZUkp_BU9H"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "zxYGgmXZBXJW"
      },
      "outputs": [],
      "source": [
        "search = GoogleSearchAPIWrapper()\n",
        "\n",
        "requests = TextRequestsWrapper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "LZapOD7rBZTG"
      },
      "outputs": [],
      "source": [
        "toolkit = [\n",
        "    Tool(\n",
        "        name = \"Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to search google to answer questions about current events\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"Requests\",\n",
        "        func=requests.get,\n",
        "        description=\"Useful for when you to make a request to a URL\"\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "G-ZorVNnCBbT"
      },
      "outputs": [],
      "source": [
        "agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "1gHznAdQCHTd",
        "outputId": "7c37c3b3-7bd7-4c42-b037-b8a457d2dce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out what the capital of Canada is.\n",
            "Action: Search\n",
            "Action Input: \"capital of Canada\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mLooking to build credit or earn rewards? Compare our rewards, Guaranteed secured and other Guaranteed credit cards. Canada's capital is Ottawa and its three largest metropolitan areas are Toronto, Montreal, and Vancouver. Canada. A vertical triband design (red, white, red)Â ... Browse available job openings at Capital One - CA. ... Together, we will build one of Canada's leading information-based technology companies â€“ join us,Â ... Ottawa (/ËˆÉ’tÉ™wÉ™/ ( listen), /ËˆÉ’tÉ™wÉ‘Ë/; Canadian French: [É”tawÉ‘]) is the capital city of Canada. It is located in Eastern Ontario, at the confluence of theÂ ... Shopify Capital offers small business funding in the form of merchant cash advances to eligible merchants in Canada. If you live in Canada and needÂ ... A leader in the alternative asset space, TPG was built for a distinctive approach, managing assets through a principled focus on innovation. The national capital is Ottawa, Canada's fourth largest city. It lies some 250 miles (400 km) northeast of Toronto and 125 miles (200 km) west of Montreal,Â ... Download Capital One Canada and enjoy it on your iPhone, iPad and iPod touch. ... Simply use your existing Capital One online banking username and passwordÂ ... Coast Capital locations are closed on Saturday, May 20 and Monday, ... Coast Capital Savings Federal Credit Union is a member of the Canada DepositÂ ... May 9, 2023 ... Ottawa, city, capital of Canada, located in southeastern Ontario. In the eastern extreme of the province, Ottawa is situated on the southÂ ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: Ottawa is the capital of Canada.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ottawa is the capital of Canada.'"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = agent({\"input\":\"What is the capital of canada?\"})\n",
        "response['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "9pAhwnmUCJCs",
        "outputId": "4b567eff-76fa-4c9b-ea86-cb3051b6fc09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out what the comments are about\n",
            "Action: Search\n",
            "Action Input: \"comments on https://news.ycombinator.com/item?id=34425779\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAbout a month after we started Y Combinator we came up with the phrase that ... Action Input: \"comments on https://news.ycombinator.com/item?id=34425779\"Â ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the comments are about the history of Y Combinator\n",
            "Final Answer: The comments on the webpage are about the history of Y Combinator.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The comments on the webpage are about the history of Y Combinator.'"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = agent({\"input\":\"Tell me what the comments are about on this webpage https://news.ycombinator.com/item?id=34425779\"})\n",
        "response['output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DM56pItBCifO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
