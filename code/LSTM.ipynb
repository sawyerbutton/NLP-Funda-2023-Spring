{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00a7e14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 包的导入\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential     \n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Activation\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4846c9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>首春:寒随穷律变，春逐鸟声开。初风飘带柳，晚雪间花梅。碧林青旧竹，绿沼翠新苔。芝田初雁去，绮...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>初晴落景:晚霞聊自怡，初晴弥可喜。日晃百花色，风动千林翠。池鱼跃不同，园鸟声还异。寄言博通者...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>初夏:一朝春夏改，隔夜鸟花迁。阴阳深浅叶，晓夕重轻烟。哢莺犹响殿，横丝正网天。珮高兰影接，绶...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>度秋:夏律昨留灰，秋箭今移晷。峨嵋岫初出，洞庭波渐起。桂白发幽岩，菊黄开灞涘。运流方可叹，含...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>仪鸾殿早秋:寒惊蓟门叶，秋发小山枝。松阴背日转，竹影避风移。提壶菊花岸，高兴芙蓉池。欲知凉气...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  首春:寒随穷律变，春逐鸟声开。初风飘带柳，晚雪间花梅。碧林青旧竹，绿沼翠新苔。芝田初雁去，绮...\n",
       "1  初晴落景:晚霞聊自怡，初晴弥可喜。日晃百花色，风动千林翠。池鱼跃不同，园鸟声还异。寄言博通者...\n",
       "2  初夏:一朝春夏改，隔夜鸟花迁。阴阳深浅叶，晓夕重轻烟。哢莺犹响殿，横丝正网天。珮高兰影接，绶...\n",
       "3  度秋:夏律昨留灰，秋箭今移晷。峨嵋岫初出，洞庭波渐起。桂白发幽岩，菊黄开灞涘。运流方可叹，含...\n",
       "4  仪鸾殿早秋:寒惊蓟门叶，秋发小山枝。松阴背日转，竹影避风移。提壶菊花岸，高兴芙蓉池。欲知凉气..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 展示数据\n",
    "poems_text = pd.read_table('poems.txt', header=None)\n",
    "poems_text.columns = [\"text\"]\n",
    "poems_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9033631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['寒', '随', '穷', '律', '变', '春', '逐', '鸟', '声', '开', '初', '风', '飘', '带', '柳', '晚', '雪', '间', '花', '梅', '碧', '林', '青', '旧', '竹', '绿', '沼', '翠', '新', '苔', '芝', '田', '初', '雁', '去', '绮', '树', '巧', '莺', '来']\n",
      "43029\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# 分离标题和正文\n",
    "# 去除标题\n",
    "# 将正文补齐\n",
    "# 将正文标准化处理\n",
    "# 将正文分割成独立的单词\n",
    "\n",
    "f = open('poems.txt',\"r\",encoding='utf-8')\n",
    "poems = []\n",
    "for line in f.readlines():\n",
    "  try:\n",
    "    title, poem = line.strip().split(':')\n",
    "    poem = poem.replace(' ','')\n",
    "    poem = poem.replace('\\n','')\n",
    "    poem = poem.replace('，', '')\n",
    "    poem = poem.replace('。','')\n",
    "    poems.append(list(poem))\n",
    "  except ValueError as e:\n",
    "    pass\n",
    "\n",
    "print(poems[0][:])\n",
    "print(len(poems)) # 一共4w3千条诗文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc12ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts(poems) # 将文本标签化并生成文本字典\n",
    "vocab_size=len(tokenizer.word_index)+1 # 字典的长度是token 下标 + 1\n",
    "poems_digit = tokenizer.texts_to_sequences(poems) # 将文本转化为数字的序列\n",
    "poems_digit = pad_sequences(poems_digit,maxlen=50,padding='post') # 对输入文本进行补齐，padding使用后补全"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2eb861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  55,  181,  343, 1203,  560,   17,  390,  155,   58,   85,  166,\n",
       "          4,  456,  364,  198,  193,  113,  159,   14,  623,  210,  127,\n",
       "         51,  139,  176,  208, 1737,  238,   82,  483, 1217,  369,  166,\n",
       "        311,   36,  791,   87, 1428,  596,   11,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_digit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f384de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=poems_digit[:,:-1]\n",
    "Y=poems_digit[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "820fa4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43029, 49)\n",
      "(43029, 49)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7590ed57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43029, 49, 7556)\n"
     ]
    }
   ],
   "source": [
    "# from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "Y = to_categorical(Y,num_classes=vocab_size) # 将Y 转化为 one-hot 向量\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "643fbe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 49, 128)           967168    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 49, 64)            49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 49, 7556)          491140    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 49, 7556)          0         \n",
      "=================================================================\n",
      "Total params: 1,507,716\n",
      "Trainable params: 1,507,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential     \n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Activation\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "hidden_size1=128\n",
    "hidden_size2=64\n",
    "# 将一些网络层通过.add()堆叠起来，就构成了一个模型\n",
    "model = Sequential()\n",
    "# 一个Embedding 层\n",
    "model.add(Embedding(input_dim=vocab_size,output_dim=hidden_size1,input_length=49,mask_zero=True))\n",
    "# 一个 LSTM 层\n",
    "model.add(LSTM(hidden_size2,return_sequences=True))\n",
    "# 一个全连接层\n",
    "model.add(Dense(vocab_size))\n",
    "# 一个softmax归一化函数\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58ed00c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "538/538 [==============================] - 294s 538ms/step - loss: 5.7265 - accuracy: 0.0262 - val_loss: 5.2097 - val_accuracy: 0.0503\n",
      "Epoch 2/10\n",
      "538/538 [==============================] - 270s 501ms/step - loss: 5.2870 - accuracy: 0.0637 - val_loss: 4.9997 - val_accuracy: 0.0700\n",
      "Epoch 3/10\n",
      "538/538 [==============================] - 271s 503ms/step - loss: 5.0985 - accuracy: 0.0767 - val_loss: 4.9237 - val_accuracy: 0.0777\n",
      "Epoch 4/10\n",
      "538/538 [==============================] - 272s 505ms/step - loss: 4.9979 - accuracy: 0.0837 - val_loss: 4.8858 - val_accuracy: 0.0820\n",
      "Epoch 5/10\n",
      "538/538 [==============================] - 268s 498ms/step - loss: 4.9258 - accuracy: 0.0882 - val_loss: 4.8652 - val_accuracy: 0.0846\n",
      "Epoch 6/10\n",
      "538/538 [==============================] - 266s 494ms/step - loss: 4.8739 - accuracy: 0.0917 - val_loss: 4.8523 - val_accuracy: 0.0861\n",
      "Epoch 7/10\n",
      "538/538 [==============================] - 266s 494ms/step - loss: 4.8356 - accuracy: 0.0943 - val_loss: 4.8487 - val_accuracy: 0.0865\n",
      "Epoch 8/10\n",
      "538/538 [==============================] - 271s 504ms/step - loss: 4.8037 - accuracy: 0.0962 - val_loss: 4.8463 - val_accuracy: 0.0871\n",
      "Epoch 9/10\n",
      "538/538 [==============================] - 275s 511ms/step - loss: 4.7784 - accuracy: 0.0981 - val_loss: 4.8476 - val_accuracy: 0.0875\n",
      "Epoch 10/10\n",
      "538/538 [==============================] - 273s 507ms/step - loss: 4.7573 - accuracy: 0.0993 - val_loss: 4.8533 - val_accuracy: 0.0881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x658534be0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# 分类交叉熵进行损失计算，使用 Learning Rate = 0.01 的优化器进行优化\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.01),metrics=['accuracy'])\n",
    "# 训练10次，每次64个batch，每个batch中traning 和 validation 的比例是4:1\n",
    "model.fit(X,Y,epochs=10,batch_size=64,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bfe2146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Poetry_LSTM.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "508f869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('Poetry_LSTM.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e01c5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "雨里春风起\n",
      "轩车不可寻\n",
      "可怜南国士\n",
      "爱君不可见\n"
     ]
    }
   ],
   "source": [
    "poem_incomplete='雨****轩****可****爱****'\n",
    "poem_index=[]\n",
    "poem_text=''\n",
    "for i in range(len(poem_incomplete)):\n",
    "    current_word=poem_incomplete[i]\n",
    "    \n",
    "    if current_word !='*':\n",
    "        index=tokenizer.word_index[current_word]\n",
    "        \n",
    "    else:\n",
    "        x=np.expand_dims(poem_index,axis=0) # 使用已有的poem_index 内容进行预测\n",
    "        x=pad_sequences(x,maxlen=49,padding='post') # 输入内容padding补齐\n",
    "        y=model.predict(x)[0,i] # 预测输出结果\n",
    "        \n",
    "        y[0]=0\n",
    "        index=y.argmax()\n",
    "        current_word=tokenizer.index_word[index] # 将输出结果的概率转化为文本内容\n",
    "        \n",
    "    poem_index.append(index)\n",
    "    poem_text=poem_text+current_word\n",
    "    \n",
    "poem_text=poem_text[0:]\n",
    "print(poem_text[0:5])\n",
    "print(poem_text[5:10])\n",
    "print(poem_text[10:15])\n",
    "print(poem_text[15:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c78f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
